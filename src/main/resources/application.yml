server:
  port: 8083
  tomcat:
    uri-encoding: UTF-8
    max-threads: 500
  servlet:
    context-path: /dns
spring:
  redis:
    #    cluster:
    #      nodes: 10.13.199.89:6372,10.13.199.89:6373,10.13.199.89:6374,10.13.199.89:6375,10.13.199.89:6376,10.13.199.89:6377
    jedis:
      pool:
        max-active: 2000
        min-idle: 8
        max-wait: 20ms
    timeout: 5000ms
    host: 172.30.154.203
    port: 6377
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      driver-class-name: com.mysql.jdbc.Driver
      url: jdbc:mysql://172.30.154.204:3306/crawler?useUnicode=true&useSSL=false&allowMultiQueries=true
      username: root
      password: 123456
      initial-size: 5
      min-idle: 5
      max-active: 100
      max-wait: 60000
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 'x'
      test-while-idle: true
      test-on-borrow: false
      pool-prepared-statements: false
      max-pool-prepared-statement-per-connection-size: 20
  freemarker:
    charset: UTF-8
    suffix: .ftl
    content-type: text/html; charset=utf-8
    template-loader-path=classpath: /templates/**
    request-context-attribute: dn
    cache: true
  devtools:
    restart:
      enabled: true
      additional-paths: src/main/java
  mvc:
    static-path-pattern: /static/**


# clickhouse
#  datasource:
#    type: com.alibaba.druid.pool.DruidDataSource
#    driver-class-name: ru.yandex.clickhouse.ClickHouseDriver
#    url: jdbc:clickhouse://172.30.154.50:8123/analysis
#    username:
#    password:


mybatis:
  mapper-locations: classpath:mapping/*.xml
  configuration:
    map-underscore-to-camel-case: true #启用驼峰是命名。
  type-aliases-package: com.surfilter.entity
# 插件配置 pagehelper
pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  params: count=countSql



#启动SeimiCrawler
#seimi:
#  crawler:
#    enabled: true
#    names: basic

#配置读取写入文件路径

base:
  info:
    urlReadPath: /data/url_data/
    sysSole: web    #nomal 正常爬虫程序。   nmap   nmap 程序。  whois模式  web模式
redis-info:
  key:
    whileUrl: domain_whilt_url # 网站白名单。
    domainUrl: domain_url #
    crawlerQueue: crawler_queue
    analiseQueue: analise_queue
    fidelityIp: fidelity_ip
    crawlerCache: crawler_cache
    PhishingUrl: phishing_url #钓鱼 网站黑名单

job:
  param:
    fiedlityJob: 0 0 1 * * ?
    #crawlerJob: 0 0 3 * * ?
    crawlerJob: 0/25 * * * * ?
    domainUrlJob: 0 0/10 * * * ?
    nmapJob: 0 0/10 * * * ?
    whoisJob: 0/30 * * * * ?

logging:
  level:
    com.surfilter.dao: debug
