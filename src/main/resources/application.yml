server:
  port: 8083
  tomcat:
    uri-encoding: UTF-8
spring:
  redis:
#    cluster:
#      nodes: 10.13.199.89:6372,10.13.199.89:6373,10.13.199.89:6374,10.13.199.89:6375,10.13.199.89:6376,10.13.199.89:6377
    jedis:
      pool:
        max-active: 2000
        min-idle: 8
        max-wait: 20ms
    timeout: 5000ms
    host: 172.30.154.203
    port: 6361
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      driver-class-name: com.mysql.jdbc.Driver
      url: jdbc:mysql://172.30.154.203:3306/crawler?characterEncoding=utf8&useSSL=true&allowMultiQueries=true
      username: root
      password: 123456
      initial-size: 5
      min-idle: 5
      max-active: 100
      max-wait: 60000
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 'x'
      test-while-idle: true
      test-on-borrow: false
      pool-prepared-statements: false
      max-pool-prepared-statement-per-connection-size: 20

# clickhouse
#  datasource:
#    type: com.alibaba.druid.pool.DruidDataSource
#    driver-class-name: ru.yandex.clickhouse.ClickHouseDriver
#    url: jdbc:clickhouse://172.30.154.50:8123/analysis
#    username:
#    password:


mybatis:
  mapper-locations: classpath:mapping/*.xml
  configuration:
    map-underscore-to-camel-case: true #启用驼峰是命名。
  type-aliases-package: com.surfilter.entity

#启动SeimiCrawler
#seimi:
#  crawler:
#    enabled: true
#    names: basic

#配置读取写入文件路径

base:
  info:
    urlReadPath: D:/data/url_data/
    sysSole: nmap    #nomal 正常爬虫程序。   nmap   nmap 程序。  whois模式。
redis-info:
  key:
    whileUrl: domain_whilt_url
    domainUrl: domain_url
    crawlerQueue: crawler_queue
    analiseQueue: analise_queue
    fidelityIp: fidelity_ip
    crawlerCache: crawler_cache

job:
  param:
    fiedlityJob: 0 0 1 * * ?
    #crawlerJob: 0 0 3 * * ?
    crawlerJob: 0/25 * * * * ?
    domainUrlJob: 0 0/10 * * * ?
    nmapJob: 0 0/10 * * * ?
    whoisJob: 0/30 * * * * ?
logging:
  file: D:/log/server.log

